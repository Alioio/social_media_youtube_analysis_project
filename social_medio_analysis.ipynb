{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overhead-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import googleapiclient.discovery\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developed-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-china",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-integral",
   "metadata": {},
   "source": [
    "#### Getting a list with videos\n",
    "\n",
    "List of videos using the YouTube Data API [YouTube Data API](https://tools.digitalmethods.net/netvizz/youtube/mod_videos_list.php)\n",
    "\n",
    "Querying for the terms: `Global warming`, `Climate change`, `Paris agreement`, `Climate realism`.\n",
    "\n",
    "#### Getting all comments (including replies) to all videos in the list\n",
    "\n",
    "Get all comments to a video using the [CommentThreads method of YouTube Developer API](https://developers.google.com/youtube/v3/docs/commentThreads/list)\n",
    "\n",
    "The API documentation of CommentsThread states that it might not contain all replies: \n",
    "\n",
    ">A commentThread resource contains information about a YouTube comment thread, which comprises a top-level comment and replies, if any exist, to that comment. A commentThread resource can represent comments about either a video or a channel.\n",
    "\n",
    ">Both the top-level comment and the replies are actually comment resources nested inside the commentThread resource. The commentThread resource does not necessarily contain all replies to a comment, and you need to use the comments.list method if you want to retrieve all replies for a particular comment. Also note that some comments do not have replies.\n",
    "\n",
    "Therefore we use the [Coments list method](https://developers.google.com/youtube/v3/docs/commentThreads/list) to get all replies to a comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alternative-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyCo58wzF-1eZXXTvb71cUJlzBJ2a9Dt3ms'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-magazine",
   "metadata": {},
   "source": [
    "#### List of vidoes containing the term `Paris agreement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "narrative-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data_raw/videolist_search50_2021_01_19-13_55_33.tab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "silver-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos(data_path, min_comments_count = 3):\n",
    "    videos = pd.read_csv(data_path, sep='\\t',header=(0))\n",
    "    #remove entries where commentCount is None\n",
    "    videos = videos.dropna(how='all', subset=['commentCount'])\n",
    "    #remove videos where comments count is lesser then minimum\n",
    "    videos.drop(videos[videos['commentCount'] < min_comments_count].index, inplace = True)\n",
    "    videos = videos.sort_values(['commentCount'], ascending=[False])  \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "urban-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = load_videos(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prompt-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>videoId</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>publishedAtSQL</th>\n",
       "      <th>videoTitle</th>\n",
       "      <th>videoDescription</th>\n",
       "      <th>tags</th>\n",
       "      <th>videoCategoryId</th>\n",
       "      <th>videoCategoryLabel</th>\n",
       "      <th>duration</th>\n",
       "      <th>durationSec</th>\n",
       "      <th>dimension</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "      <th>thumbnail_maxres</th>\n",
       "      <th>licensedContent</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UC3XTzVzaHQEd30rQbuvCtTQ</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>5scez5dqtAc</td>\n",
       "      <td>2017-06-05T06:30:00Z</td>\n",
       "      <td>2017-06-05 06:30:00</td>\n",
       "      <td>Paris Agreement: Last Week Tonight with John Oliver (HBO)</td>\n",
       "      <td>Donald Trump plans to withdraw the United States from the Paris agreement on climate change. That's bad news for anyone who happens to live on this planet. Connect with Last Week Tonight online... Subscribe to the Last Week Tonight YouTube channel for more almost news as it almost happens: www.youtube.com/user/LastWeekTonight Find Last Week Tonight on Facebook like your mom would: http://Facebook.com/LastWeekTonight Follow us on Twitter for news about jokes and jokes about news: http://Twitter.com/LastWeekTonight Visit our official site for all that other stuff at once: http://www.hbo.com/lastweektonight</td>\n",
       "      <td>last week tonight paris agreement,paris accord,john oliver paris agreement</td>\n",
       "      <td>24</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>PT20M58S</td>\n",
       "      <td>1258</td>\n",
       "      <td>2d</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.ytimg.com/vi/5scez5dqtAc/maxresdefault.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13021725</td>\n",
       "      <td>176853</td>\n",
       "      <td>12626</td>\n",
       "      <td>0</td>\n",
       "      <td>13747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>UC2LZO6swZ9SLUEOks3WnsfA</td>\n",
       "      <td>2veritasium</td>\n",
       "      <td>1WKoj-kodBw</td>\n",
       "      <td>2017-06-02T21:17:43Z</td>\n",
       "      <td>2017-06-02 21:17:43</td>\n",
       "      <td>5 Bad Reasons to Ditch the Paris Climate Agreement</td>\n",
       "      <td>I've heard a lot of reasons for withdrawing from the Paris climate agreement but none of them makes sense to me. Here are some links that support my thinking: BC Carbon tax and impact: https://en.wikipedia.org/wiki/British_Columbia_carbon_tax Popular opinion about the Paris Climate Agreement: https://fivethirtyeight.com/features/was-trumps-paris-exit-good-politics/ http://climatecommunication.yale.edu/publications/paris_agreement_by_state/ India and China pledges: http://www.climatechangenews.com/2017/05/15/india-china-track-exceed-paris-climate-pledges/ Exxon Mobil support for Paris Agreement: https://www.bloomberg.com/news/articles/2017-05-31/exxon-conoco-back-paris-climate-deal-as-trump-weighs-pact-exit</td>\n",
       "      <td>veritasium,paris,donald trump,trump,climate change,global warming,paris climate agreement,withdrawal,leave,united states,agreement,climate,policy,politics,science</td>\n",
       "      <td>27</td>\n",
       "      <td>Education</td>\n",
       "      <td>PT8M43S</td>\n",
       "      <td>523</td>\n",
       "      <td>2d</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>https://i.ytimg.com/vi/1WKoj-kodBw/maxresdefault.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>631855</td>\n",
       "      <td>36675</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>6234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>UCGaVdbSav8xWuFWTadK6loA</td>\n",
       "      <td>vlogbrothers</td>\n",
       "      <td>Sr2J_1J9w3A</td>\n",
       "      <td>2017-06-02T18:18:15Z</td>\n",
       "      <td>2017-06-02 18:18:15</td>\n",
       "      <td>The Paris Accord: What is it? And What Does it All Mean?</td>\n",
       "      <td>At the heart of the desire to get America out of the Paris Agreement seems to be three things: 1. Nostalgia. The focus on coal, an energy source that is becoming uneconomical even in developing countries, and that employs very few people in America can't have anything to do with anything except an imagined fondness for a world that probably never existed. These people are right that fossil fuels have been great for Americans and also for the world. I think the people who worked and fought to use fossil fuels to make people's lives better did good things. I also think we need new paths and to retire old ones. 2. A push to have countries care only about their own interests. Climate change is the best example that this doesn't work. And that's very scary for people who are skeptical of globalism. It may seem to them awfully convenient that the people who want a more global society happened to find this disaster that can only be solved by a more global society. Of course there are some that are purely economically motivated, but while those people are powerful, there aren't many of them. But these are the things that really resonate with large numbers of people. And when you're trying to defend your worldview, you'll make some magnificent mental leaps to do it...like that every scientist ever is lying about how CO2 absorption works. There are a couple Twitter threads that I really enjoyed on these topics. here they are. Vi Hart: https://twitter.com/vihartvihart/status/870413832732250112 Adam Conover: https://twitter.com/adamconover/status/870025080041910272 ---- Subscribe to our newsletter! http://nerdfighteria.com/newsletter/ And join the community at http://nerdfighteria.com http://effyeahnerdfighters.com Help transcribe videos - http://nerdfighteria.info John's twitter - http://twitter.com/johngreen John's tumblr - http://fishingboatproceeds.tumblr.com Hank's twitter - http://twitter.com/hankgreen Hank's tumblr - http://edwardspoonhands.tumblr.com</td>\n",
       "      <td>climate change,paris agreement,paris accord,paris,global warming,donald trump,syria,climate agreement,climate accord,united nations,UN,news,europe</td>\n",
       "      <td>22</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>PT5M54S</td>\n",
       "      <td>354</td>\n",
       "      <td>2d</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>https://i.ytimg.com/vi/Sr2J_1J9w3A/maxresdefault.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>799709</td>\n",
       "      <td>42382</td>\n",
       "      <td>3143</td>\n",
       "      <td>0</td>\n",
       "      <td>4193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>UC16niRr50-MSBwiO3YDb3RA</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>jP55meWlLt4</td>\n",
       "      <td>2017-06-01T20:11:03Z</td>\n",
       "      <td>2017-06-01 20:11:03</td>\n",
       "      <td>Trumps pulls US out of Paris climate deal - BBC News</td>\n",
       "      <td>President Donald Trump has announced that the US is withdrawing from the 2015 Paris climate agreement. He said moves to negotiate a new deal that would not disadvantage the US would begin. Mr Trump said during last year's presidential election campaign that he would take the step to help his country's oil and coal industries. Opponents say withdrawing from the accord is an abdication of US leadership on a key global challenge. Please subscribe HERE http://bit.ly/1rbfUog World In Pictures https://www.youtube.com/playlist?list=PLS3XGZxi7cBX37n4R0UGJN-TLiQOm7ZTP Big Hitters https://www.youtube.com/playlist?list=PLS3XGZxi7cBUME-LUrFkDwFmiEc3jwMXP Just Good News https://www.youtube.com/playlist?list=PLS3XGZxi7cBUsYo_P26cjihXLN-k3w246</td>\n",
       "      <td>paris climate,paris,paris climate deal,bbc news,bbc,news,youtube,video,donald trump,trump news,breaking,breaking news,paris climate trump,trump paris climate,china,climate change,2015 Paris climate agreement,paris climate agreement</td>\n",
       "      <td>25</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>PT3M35S</td>\n",
       "      <td>215</td>\n",
       "      <td>2d</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158965</td>\n",
       "      <td>1226</td>\n",
       "      <td>2436</td>\n",
       "      <td>0</td>\n",
       "      <td>1768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>UCAuUUnT6oDeKwE6v1NGQxug</td>\n",
       "      <td>TED</td>\n",
       "      <td>k1oPVp63eNk</td>\n",
       "      <td>2020-10-29T22:00:54Z</td>\n",
       "      <td>2020-10-29 22:00:54</td>\n",
       "      <td>The state of the climate crisis | Climate Action Tracker</td>\n",
       "      <td>Take action on climate change at http://countdown.ted.com. With the 2015 Paris Climate Agreement, 197 countries agreed to set emission targets that would limit global temperature rise 1.5 degrees Celsius by capping greenhouse emissions at \"net-zero\" -- or absorbing as much carbon as they emit -- by 2050. So far, only two countries (Gambia and Morocco) are hitting their targets, while the biggest emitters are falling flat, or ignoring their goals entirely. How can we hold these countries accountable? Enter the Climate Action Tracker. This video was part of the Countdown Global Launch on 10.10.2020. (Watch the full event here: https://youtu.be/5dVcn8NjbwY.) Countdown is TED's global initiative to accelerate solutions to the climate crisis. The goal: to build a better future by cutting greenhouse gas emissions in half by 2030, in the race to a zero-carbon world. Get involved at https://countdown.ted.com/sign-up Follow Countdown on Twitter: http://twitter.com/tedcountdown Follow Countdown on Instagram: http://instagram.com/tedcountdown Subscribe to our channel: http://youtube.com/TED TED's videos may be used for non-commercial purposes under a Creative Commons License, Attribution–Non Commercial–No Derivatives (or the CC BY – NC – ND 4.0 International) and in accordance with our TED Talks Usage Policy (https://www.ted.com/about/our-organization/our-policies-terms/ted-talks-usage-policy). For more information on using TED for commercial purposes (e.g. employee learning, in a film or online course), please submit a Media Request at https://media-requests.ted.com</td>\n",
       "      <td>TEDTalk,TEDTalks,TED Talk,TED Talks,Climate Action Tracker,Climate Change,Science,Environment,Countdown,Energy,Sustainability,Data</td>\n",
       "      <td>28</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>PT4M27S</td>\n",
       "      <td>267</td>\n",
       "      <td>2d</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>https://i.ytimg.com/vi/k1oPVp63eNk/maxresdefault.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111700</td>\n",
       "      <td>4833</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>1153.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    position                 channelId     channelTitle      videoId  \\\n",
       "0          1  UC3XTzVzaHQEd30rQbuvCtTQ  LastWeekTonight  5scez5dqtAc   \n",
       "16        17  UC2LZO6swZ9SLUEOks3WnsfA      2veritasium  1WKoj-kodBw   \n",
       "26        27  UCGaVdbSav8xWuFWTadK6loA     vlogbrothers  Sr2J_1J9w3A   \n",
       "21        22  UC16niRr50-MSBwiO3YDb3RA         BBC News  jP55meWlLt4   \n",
       "25        26  UCAuUUnT6oDeKwE6v1NGQxug              TED  k1oPVp63eNk   \n",
       "\n",
       "             publishedAt       publishedAtSQL  \\\n",
       "0   2017-06-05T06:30:00Z  2017-06-05 06:30:00   \n",
       "16  2017-06-02T21:17:43Z  2017-06-02 21:17:43   \n",
       "26  2017-06-02T18:18:15Z  2017-06-02 18:18:15   \n",
       "21  2017-06-01T20:11:03Z  2017-06-01 20:11:03   \n",
       "25  2020-10-29T22:00:54Z  2020-10-29 22:00:54   \n",
       "\n",
       "                                                   videoTitle  \\\n",
       "0   Paris Agreement: Last Week Tonight with John Oliver (HBO)   \n",
       "16         5 Bad Reasons to Ditch the Paris Climate Agreement   \n",
       "26   The Paris Accord: What is it? And What Does it All Mean?   \n",
       "21       Trumps pulls US out of Paris climate deal - BBC News   \n",
       "25   The state of the climate crisis | Climate Action Tracker   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                videoDescription  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Donald Trump plans to withdraw the United States from the Paris agreement on climate change. That's bad news for anyone who happens to live on this planet. Connect with Last Week Tonight online... Subscribe to the Last Week Tonight YouTube channel for more almost news as it almost happens: www.youtube.com/user/LastWeekTonight Find Last Week Tonight on Facebook like your mom would: http://Facebook.com/LastWeekTonight Follow us on Twitter for news about jokes and jokes about news: http://Twitter.com/LastWeekTonight Visit our official site for all that other stuff at once: http://www.hbo.com/lastweektonight   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I've heard a lot of reasons for withdrawing from the Paris climate agreement but none of them makes sense to me. Here are some links that support my thinking: BC Carbon tax and impact: https://en.wikipedia.org/wiki/British_Columbia_carbon_tax Popular opinion about the Paris Climate Agreement: https://fivethirtyeight.com/features/was-trumps-paris-exit-good-politics/ http://climatecommunication.yale.edu/publications/paris_agreement_by_state/ India and China pledges: http://www.climatechangenews.com/2017/05/15/india-china-track-exceed-paris-climate-pledges/ Exxon Mobil support for Paris Agreement: https://www.bloomberg.com/news/articles/2017-05-31/exxon-conoco-back-paris-climate-deal-as-trump-weighs-pact-exit   \n",
       "26  At the heart of the desire to get America out of the Paris Agreement seems to be three things: 1. Nostalgia. The focus on coal, an energy source that is becoming uneconomical even in developing countries, and that employs very few people in America can't have anything to do with anything except an imagined fondness for a world that probably never existed. These people are right that fossil fuels have been great for Americans and also for the world. I think the people who worked and fought to use fossil fuels to make people's lives better did good things. I also think we need new paths and to retire old ones. 2. A push to have countries care only about their own interests. Climate change is the best example that this doesn't work. And that's very scary for people who are skeptical of globalism. It may seem to them awfully convenient that the people who want a more global society happened to find this disaster that can only be solved by a more global society. Of course there are some that are purely economically motivated, but while those people are powerful, there aren't many of them. But these are the things that really resonate with large numbers of people. And when you're trying to defend your worldview, you'll make some magnificent mental leaps to do it...like that every scientist ever is lying about how CO2 absorption works. There are a couple Twitter threads that I really enjoyed on these topics. here they are. Vi Hart: https://twitter.com/vihartvihart/status/870413832732250112 Adam Conover: https://twitter.com/adamconover/status/870025080041910272 ---- Subscribe to our newsletter! http://nerdfighteria.com/newsletter/ And join the community at http://nerdfighteria.com http://effyeahnerdfighters.com Help transcribe videos - http://nerdfighteria.info John's twitter - http://twitter.com/johngreen John's tumblr - http://fishingboatproceeds.tumblr.com Hank's twitter - http://twitter.com/hankgreen Hank's tumblr - http://edwardspoonhands.tumblr.com   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            President Donald Trump has announced that the US is withdrawing from the 2015 Paris climate agreement. He said moves to negotiate a new deal that would not disadvantage the US would begin. Mr Trump said during last year's presidential election campaign that he would take the step to help his country's oil and coal industries. Opponents say withdrawing from the accord is an abdication of US leadership on a key global challenge. Please subscribe HERE http://bit.ly/1rbfUog World In Pictures https://www.youtube.com/playlist?list=PLS3XGZxi7cBX37n4R0UGJN-TLiQOm7ZTP Big Hitters https://www.youtube.com/playlist?list=PLS3XGZxi7cBUME-LUrFkDwFmiEc3jwMXP Just Good News https://www.youtube.com/playlist?list=PLS3XGZxi7cBUsYo_P26cjihXLN-k3w246   \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                Take action on climate change at http://countdown.ted.com. With the 2015 Paris Climate Agreement, 197 countries agreed to set emission targets that would limit global temperature rise 1.5 degrees Celsius by capping greenhouse emissions at \"net-zero\" -- or absorbing as much carbon as they emit -- by 2050. So far, only two countries (Gambia and Morocco) are hitting their targets, while the biggest emitters are falling flat, or ignoring their goals entirely. How can we hold these countries accountable? Enter the Climate Action Tracker. This video was part of the Countdown Global Launch on 10.10.2020. (Watch the full event here: https://youtu.be/5dVcn8NjbwY.) Countdown is TED's global initiative to accelerate solutions to the climate crisis. The goal: to build a better future by cutting greenhouse gas emissions in half by 2030, in the race to a zero-carbon world. Get involved at https://countdown.ted.com/sign-up Follow Countdown on Twitter: http://twitter.com/tedcountdown Follow Countdown on Instagram: http://instagram.com/tedcountdown Subscribe to our channel: http://youtube.com/TED TED's videos may be used for non-commercial purposes under a Creative Commons License, Attribution–Non Commercial–No Derivatives (or the CC BY – NC – ND 4.0 International) and in accordance with our TED Talks Usage Policy (https://www.ted.com/about/our-organization/our-policies-terms/ted-talks-usage-policy). For more information on using TED for commercial purposes (e.g. employee learning, in a film or online course), please submit a Media Request at https://media-requests.ted.com   \n",
       "\n",
       "                                                                                                                                                                                                                                       tags  \\\n",
       "0                                                                                                                                                                last week tonight paris agreement,paris accord,john oliver paris agreement   \n",
       "16                                                                       veritasium,paris,donald trump,trump,climate change,global warming,paris climate agreement,withdrawal,leave,united states,agreement,climate,policy,politics,science   \n",
       "26                                                                                       climate change,paris agreement,paris accord,paris,global warming,donald trump,syria,climate agreement,climate accord,united nations,UN,news,europe   \n",
       "21  paris climate,paris,paris climate deal,bbc news,bbc,news,youtube,video,donald trump,trump news,breaking,breaking news,paris climate trump,trump paris climate,china,climate change,2015 Paris climate agreement,paris climate agreement   \n",
       "25                                                                                                       TEDTalk,TEDTalks,TED Talk,TED Talks,Climate Action Tracker,Climate Change,Science,Environment,Countdown,Energy,Sustainability,Data   \n",
       "\n",
       "    videoCategoryId    videoCategoryLabel  duration  durationSec dimension  \\\n",
       "0                24         Entertainment  PT20M58S         1258        2d   \n",
       "16               27             Education   PT8M43S          523        2d   \n",
       "26               22        People & Blogs   PT5M54S          354        2d   \n",
       "21               25       News & Politics   PT3M35S          215        2d   \n",
       "25               28  Science & Technology   PT4M27S          267        2d   \n",
       "\n",
       "   definition  caption                                      thumbnail_maxres  \\\n",
       "0          hd    False  https://i.ytimg.com/vi/5scez5dqtAc/maxresdefault.jpg   \n",
       "16         hd     True  https://i.ytimg.com/vi/1WKoj-kodBw/maxresdefault.jpg   \n",
       "26         hd     True  https://i.ytimg.com/vi/Sr2J_1J9w3A/maxresdefault.jpg   \n",
       "21         hd    False                                                   NaN   \n",
       "25         hd     True  https://i.ytimg.com/vi/k1oPVp63eNk/maxresdefault.jpg   \n",
       "\n",
       "    licensedContent  viewCount  likeCount  dislikeCount  favoriteCount  \\\n",
       "0               1.0   13021725     176853         12626              0   \n",
       "16              1.0     631855      36675          5337              0   \n",
       "26              1.0     799709      42382          3143              0   \n",
       "21              1.0     158965       1226          2436              0   \n",
       "25              1.0     111700       4833           531              0   \n",
       "\n",
       "    commentCount  \n",
       "0        13747.0  \n",
       "16        6234.0  \n",
       "26        4193.0  \n",
       "21        1768.0  \n",
       "25        1153.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-executive",
   "metadata": {},
   "source": [
    "We need to find more videos with more than a minimum number of comments. E.g. 2 comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "educational-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have in total 33282.0 from comments distributed in 40 for videos containing the term Paris Agreement.\n",
      "Mean commen count: 832.05 Median: 115.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have in total {np.sum(videos['commentCount'])} from comments distributed in {len(videos)} for videos containing the term Paris Agreement.\")\n",
    "print(f\"Mean commen count: {np.mean(videos['commentCount'])} Median: {np.median(videos['commentCount'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liable-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'MIA_1xQc7x8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "urban-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Concat video lists remove duplicates based on videoId\n",
    "#TODO: find number of users commented multiple videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-midwest",
   "metadata": {},
   "source": [
    "#### Class to load all comments of a video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floppy-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video_comments:\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key  = api_key\n",
    "        #self.video_id = video_id\n",
    "        self.max_results = 100     \n",
    "        comments_df = pd.DataFrame({\n",
    "                            'id':[],\n",
    "                            'threadId':[],\n",
    "                            'published_at': [], \n",
    "                            'author_name': [], \n",
    "                            'text': [],\n",
    "                            'is_reply': [],\n",
    "                            'likeCount': [],\n",
    "                            'cleaned': [],\n",
    "                            'video_id': [],\n",
    "                            'video_published_at': []}, \n",
    "                            columns = [ 'id',\n",
    "                                        'threadId',\n",
    "                                        'published_at', \n",
    "                                        'author_name', \n",
    "                                        'text', \n",
    "                                        'likeCount',\n",
    "                                        'is_reply', \n",
    "                                        'cleaned', \n",
    "                                        'video_id', \n",
    "                                        'video_published_at'])\n",
    "        self.comments_df = comments_df\n",
    "        \n",
    "    \n",
    "    '''load all replies of top level comments and append dataframe witth all top level comments and replies. \n",
    "    (appendingt to df and loading replies should be devided to different methods.)'''\n",
    "    def _add_to_dataframe(self, response):\n",
    "        for i, main_comment in enumerate(response['items']):\n",
    "            comment = main_comment['snippet']['topLevelComment']['snippet']\n",
    "\n",
    "            new_row = pd.Series(data={\n",
    "                                    'id':main_comment['snippet']['topLevelComment']['id'],\n",
    "                                    'threadId':main_comment['snippet']['topLevelComment']['id'],\n",
    "                                    'published_at':comment['publishedAt'] , \n",
    "                                    'author_name': comment['authorDisplayName'], \n",
    "                                    'text': comment['textOriginal'],\n",
    "                                    'likeCount':comment['likeCount'],\n",
    "                                    'is_reply': 0,\n",
    "                                    'video_id': comment['videoId']})\n",
    "\n",
    "            self.comments_df = self.comments_df.append(new_row, ignore_index=True)\n",
    "\n",
    "            \n",
    "            #check if the top level comment has replies. If yey then get these too and add to df\n",
    "            request_replies = requests.get(f\"https://youtube.googleapis.com/youtube/v3/comments?part=snippet&parentId={main_comment['snippet']['topLevelComment']['id']}&key={self.api_key}\")\n",
    "            response_replies = json.loads(request_replies.text)\n",
    "        \n",
    "            #if response_replies['items'] > 0 then the main comment has replies\n",
    "            if(len(response_replies['items']) > 0):\n",
    "                for i, main_reply in enumerate(response_replies['items']):      \n",
    "                    reply = main_reply['snippet']\n",
    "\n",
    "                    new_row = pd.Series(data={\n",
    "                                            'id':reply['parentId'],\n",
    "                                            'threadId':main_comment['snippet']['topLevelComment']['id'],\n",
    "                                            'published_at':reply['publishedAt'] , \n",
    "                                            'author_name': reply['authorDisplayName'], \n",
    "                                            'text': reply['textOriginal'],\n",
    "                                            'likeCount':reply['likeCount'],\n",
    "                                            'is_reply': 1,\n",
    "                                            'video_id': comment['videoId']})\n",
    "\n",
    "                    self.comments_df = self.comments_df.append(new_row, ignore_index=True)\n",
    "                    \n",
    "    \n",
    "    '''Load (and append comments dataframe) recursively comments from next page until there are no next page. '''\n",
    "    def _get_next_page(self, response):     \n",
    "        request1 = requests.get(f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&maxResults={self.max_results}&pageToken={str(response['nextPageToken'])}&videoId={self.video_id}&key={self.api_key}\")\n",
    "        response1 = json.loads(request1.text)\n",
    "        self._add_to_dataframe(response1)\n",
    "        \n",
    "        if ('nextPageToken' in response1.keys()):\n",
    "            self._get_next_page(response1)\n",
    "    \n",
    "    '''Start loading comments. Paginated.'''\n",
    "    def get_comments(self, video_id):  \n",
    "        self.video_id = video_id\n",
    "        request  = requests.get(f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&maxResults={self.max_results}&videoId={self.video_id}&key={self.api_key}\")\n",
    "        response = json.loads(request.text)     \n",
    "    \n",
    "        self._add_to_dataframe(response)\n",
    "        \n",
    "        if 'nextPageToken' in response.keys():\n",
    "            self._get_next_page(response)\n",
    "        \n",
    "        return self.comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_comments = Video_comments(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "meaningful-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments_df = vid_comments.get_comments(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "specific-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df = pd.DataFrame({\n",
    "                            'id':[],\n",
    "                            'threadId':[],\n",
    "                            'published_at': [], \n",
    "                            'author_name': [], \n",
    "                            'text': [],\n",
    "                            'is_reply': [],\n",
    "                            'likeCount': [],\n",
    "                            'cleaned': [],\n",
    "                            'video_id': [],\n",
    "                            'video_published_at': []}, \n",
    "                            columns = [ 'id',\n",
    "                                        'threadId',\n",
    "                                        'published_at', \n",
    "                                        'author_name', \n",
    "                                        'text', \n",
    "                                        'likeCount',\n",
    "                                        'is_reply', \n",
    "                                        'cleaned', \n",
    "                                        'video_id', \n",
    "                                        'video_published_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raised-atlantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13747.0\n",
      "6234.0\n",
      "4193.0\n",
      "1768.0\n",
      "1153.0\n",
      "video:  5  of  40  # of comments:  1153.0\n",
      "(1054, 10)     (1054, 10)\n",
      "2135.0\n",
      "video:  6  of  40  # of comments:  1081.0\n",
      "(3267, 10)     (2213, 10)\n",
      "3987.0\n",
      "video:  7  of  40  # of comments:  720.0\n",
      "(6198, 10)     (2931, 10)\n",
      "6842.0\n",
      "video:  8  of  40  # of comments:  644.0\n",
      "(9683, 10)     (3485, 10)\n",
      "10273.0\n",
      "10220.0\n",
      "9973.0\n",
      "9969.0\n",
      "9900.0\n",
      "9867.0\n",
      "9854.0\n",
      "9836.0\n",
      "9826.0\n",
      "9811.0\n",
      "9807.0\n",
      "9802.0\n",
      "9795.0\n",
      "9795.0\n",
      "9790.0\n",
      "9769.0\n",
      "9768.0\n",
      "9748.0\n",
      "9734.0\n",
      "9709.0\n",
      "9708.0\n",
      "9707.0\n",
      "9700.0\n",
      "9700.0\n",
      "9699.0\n",
      "9697.0\n",
      "9695.0\n",
      "9694.0\n",
      "9691.0\n",
      "9689.0\n",
      "9686.0\n",
      "9686.0\n"
     ]
    }
   ],
   "source": [
    "totalVideoCount = videos.shape[0]\n",
    "counter = 1\n",
    "max_download = 8000\n",
    "\n",
    "for i, video in videos.iterrows():\n",
    "\n",
    "    if((len(all_comments_df) + video.commentCount) < max_download):\n",
    "        if(counter > 4):\n",
    "            print('video: ',counter,' of ',totalVideoCount,' # of comments: ',video.commentCount)\n",
    "            comments_df = vid_comments.get_comments(video.videoId)\n",
    "            all_comments_df = pd.concat([all_comments_df, comments_df], axis=0)\n",
    "            print(all_comments_df.shape,'   ',comments_df.shape)\n",
    "    counter+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "veterinary-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9683, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sunrise-adolescent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# saving the DataFrame as a CSV file \n",
    "all_comments_df.to_csv('data_raw/all_comments.csv', index = True) \n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-workplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
