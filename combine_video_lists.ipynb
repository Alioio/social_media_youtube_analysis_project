{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Combine Video Lists generated with the [YouTube Data Tools](https://tools.digitalmethods.net/netvizz/youtube/index.php) \n",
    "## Usage\n",
    "\n",
    "1. go to the Variables Section below and Set/Check the desired Values. make sure the relative Paths are correct.\n",
    "2. Activate / Deactivate the desiredi Features\n",
    "3. Run the script, read output to find issues\n",
    "\n",
    "## Features\n",
    "\n",
    "- Combines Video Lists from  [YouTube Data Tools](https://tools.digitalmethods.net/netvizz/youtube/index.php) into one Master List\n",
    "- Removes Duplicate Video Entrys\n",
    "- Can Mark Downloaded Video Comments based on downloaded comment files (if video Id is included)\n",
    "- Can Mark Downloaded Video Comments based on previously created and marked master Video List\n",
    "- Can Split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set Variables and options\n",
    "\n",
    "### Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Path in case of Error C:\\Users\\moritz\\Downloads\\social analizing\\project\\git\\social_media_youtube_analysis_project\n"
     ]
    }
   ],
   "source": [
    "min_Comments = 3.0\n",
    "\n",
    "split_comment_count = 10000.0\n",
    "\n",
    "path = os.path.abspath(\"../social_media_youtube_analysis_project\")\n",
    "data_raw_path = path + \"/data_raw/videolists\" # raw video lists\n",
    "video_list_save_path = path + \"/summery_vid_lists\"\n",
    "comment_saves_path = path + \"/data_raw/comments\"\n",
    "comment_manual_saves_path = path + \"/data_raw/datatool_manual\"\n",
    "\n",
    "print(\"Check Path in case of Error \" + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_videos_from_old_list = True\n",
    "use_only_newest_video_master_list = False\n",
    "\n",
    "\n",
    "mark_videos_from_comment_files = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle Liste der Videolisten und checken der Pfade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    raise ValueError(\"Error, Check Path in 'path' variable\")\n",
    "if not os.path.exists(data_raw_path):\n",
    "    raise ValueError(\"Error, Check Path in 'data_raw_path' variable\")\n",
    "if not os.path.exists(video_list_save_path):\n",
    "    raise ValueError(\"Error, Check Path in 'video_list_save_path' variable\")\n",
    "if not os.path.exists(video_list_save_path) and mark_videos_from_comment_files:\n",
    "    raise ValueError(\"Error, Check Path in 'video_list_save_path' variable\")\n",
    "\n",
    "files = [f for f in os.listdir(data_raw_path) if os.path.isfile(os.path.join( data_raw_path , f)) and \"videolist\" in f]\n",
    "\n",
    "if not files:\n",
    "    raise ValueError('Error List is empty, no video Lists have been found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine files and insert columns for marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchtermFromFile(filename):\n",
    "    name = filename.split(\"_\")\n",
    "    name = name[7:]\n",
    "    name = \" \".join(name)\n",
    "    name = name[:-4]\n",
    "    return name\n",
    "\n",
    "firstfile = files.pop()\n",
    "combined_csv = pd.read_csv(data_raw_path +\"/\" + firstfile, sep='\\t',header=(0))\n",
    "combined_csv['search_Term'] = searchtermFromFile(firstfile)\n",
    "combined_csv['Comments_Downloaded'] = \"False\"\n",
    "combined_csv['Comments_Downloaded_Stopped_At'] = 0\n",
    "\n",
    "for filename in files:\n",
    "    filepath = data_raw_path +\"/\" + filename\n",
    "    add_csv = pd.read_csv(data_raw_path +\"/\" + filename, sep='\\t',header=(0))\n",
    "    add_csv['search_Term'] = searchtermFromFile(filename)\n",
    "    add_csv['Comments_Downloaded'] = \"False\"\n",
    "    add_csv['Comments_Downloaded_Stopped_At'] = 0\n",
    "    combined_csv = pd.concat([combined_csv, add_csv])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop duplicate videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.drop_duplicates(subset =\"videoId\", \n",
    "                     keep = False, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop videos below comment minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.drop(combined_csv[combined_csv.commentCount < min_Comments].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funktion to Export as CSV with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(export_csf):\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    " \n",
    "    # time Format\n",
    "    # YY-mm-dd-H-M-S\n",
    "    dt_string = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "    # in case path does not exist\n",
    "    if not os.path.exists(path + \"/summery_vid_lists/\"):\n",
    "        os.makedirs(path + \"/summery_vid_lists/\")\n",
    "\n",
    "    # export complete list\n",
    "    export_csf.to_csv( video_list_save_path + \"/\" + dt_string + \"_master_video_list_all.csv\", index=False, encoding='utf-8-sig', sep='\\t')\n",
    "    print(\"Complete List Exported to \" + video_list_save_path + \"/\" + dt_string + \"_master_video_list_all.csv\")\n",
    "    \n",
    "    # split by comment value\n",
    "    export_csf.sort_values(by=['commentCount'],inplace=True, axis=0,ignore_index = True,  na_position = 'first')\n",
    "    csv = export_csf\n",
    "\n",
    "    index = csv[csv.commentCount >=split_comment_count].first_valid_index()\n",
    "  \n",
    "    df1 = csv[:index]\n",
    "    df2 = csv[index:]\n",
    "    \n",
    "    \n",
    "    df1.to_csv( video_list_save_path + \"/\" + dt_string + \"_master_video_list_below_\" + str(int(split_comment_count)) + \".csv\", index=False, encoding='utf-8-sig', sep='\\t')\n",
    "    print(\"Complete List Exported to \" + video_list_save_path + \"/\" + dt_string + \"_master_video_list_below_\" + str(int(split_comment_count)) + \".csv\")\n",
    "    \n",
    "    df2.to_csv( video_list_save_path + \"/\" + dt_string + \"_master_video_list_above_\" + str(int(split_comment_count)) + \".csv\", index=False, encoding='utf-8-sig', sep='\\t')\n",
    "    print(\"Complete List Exported to \" + video_list_save_path + \"/\" + dt_string + \"_master_video_list_above_\" + str(int(split_comment_count)) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion to mark videos from old list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_from_videos():\n",
    "    # function requires filles combined_csv variable\n",
    "    files = [f for f in os.listdir(video_list_save_path) if os.path.isfile(os.path.join( video_list_save_path , f)) and \"master_video_list_all\" in f]\n",
    "    files = sorted(files)\n",
    "    print(files)\n",
    "    if use_only_newest_video_master_list:\n",
    "        files = [files[-1]]\n",
    "    for filename in files:\n",
    "        filepath =  video_list_save_path +\"/\" + filename\n",
    "        csv = pd.read_csv(filepath, header=(0), sep='\\t')\n",
    "\n",
    "        if 'Comments_Downloaded' in csv.columns:\n",
    "            csv = csv[csv.Comments_Downloaded == True]\n",
    "            for index, row in csv.iterrows():\n",
    "                combined_csv.loc[combined_csv.videoId == row.videoId, 'Comments_Downloaded'] = True\n",
    "    print(\"mark_from_videos finished\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion to mark videos from comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_from_comments():\n",
    "    files = [f for f in os.listdir(comment_saves_path) if os.path.isfile(os.path.join( comment_saves_path , f)) and \"comment\" in f]\n",
    "    for filename in files:\n",
    "        filepath =  comment_saves_path +\"/\" + filename\n",
    "        try:\n",
    "            csv = pd.read_csv(filepath,header=(0)) # eventuell sep='\\t'\n",
    "            if 'video_id' in csv.columns:\n",
    "                csv = csv.drop_duplicates('video_id', keep='last')\n",
    "                for index, row in csv.iterrows():\n",
    "                    combined_csv.loc[combined_csv.videoId == row.video_id, 'Comments_Downloaded'] = True\n",
    "            else:\n",
    "                print(\"File \" + filename + \" has no column video_id, videos not marked in list, column names are:\")\n",
    "                print(\" \")\n",
    "                print(list(csv.columns) )\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(\"Unicode Error in file \" + filename + \" Re-Save in UTF 8, could be an unprocessed manual download\") \n",
    "    print(\"mark_from_comments finished\")\n",
    "    print(\" \")\n",
    "    \n",
    "def mark_from_Manual_comments():\n",
    "    # manuel video list from comments folder\n",
    "    files = [f for f in os.listdir(comment_saves_path) if os.path.isfile(os.path.join( comment_saves_path , f)) and \"comment\" in f and \"videoinfo\" in f]\n",
    "    \n",
    "    # manuel video list from data tools folder\n",
    "    files = files + [f for f in os.listdir(comment_manual_saves_path) if os.path.isfile(os.path.join( comment_manual_saves_path , f)) and \"comment\" in f and \"videoinfo\" in f]\n",
    "    \n",
    "    # remove double entrys\n",
    "    files = list(dict.fromkeys(files))\n",
    "       \n",
    "    for filename in files:\n",
    "        # extract video id\n",
    "        file =  filename[10:]\n",
    "        videoId = file[:file.find(\"_202\")]\n",
    "        \n",
    "        # mark video\n",
    "        combined_csv.loc[combined_csv.videoId == videoId, 'Comments_Downloaded'] = True\n",
    "     \n",
    "    print(\"mark_from_comments_manual finished\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply features and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "mark_from_videos finished\n",
      " \n",
      "File videoinfo_MIA_1xQc7x8_2021_01_20-12_13_25_comments.csv has no column video_id, videos not marked in list, column names are:\n",
      " \n",
      "['id', 'replyCount', 'likeCount', 'publishedAt', 'authorName', 'text', 'authorChannelId', 'authorChannelUrl', 'isReply', 'isReplyTo', 'isReplyToName']\n",
      "mark_from_comments finished\n",
      " \n",
      "mark_from_comments_manual finished\n",
      " \n",
      "Complete List Exported to C:\\Users\\moritz\\Downloads\\social analizing\\project\\git\\social_media_youtube_analysis_project/summery_vid_lists/2021-03-09-15-12-13_master_video_list_all.csv\n",
      "Complete List Exported to C:\\Users\\moritz\\Downloads\\social analizing\\project\\git\\social_media_youtube_analysis_project/summery_vid_lists/2021-03-09-15-12-13_master_video_list_below_10000.csv\n",
      "Complete List Exported to C:\\Users\\moritz\\Downloads\\social analizing\\project\\git\\social_media_youtube_analysis_project/summery_vid_lists/2021-03-09-15-12-13_master_video_list_above_10000.csv\n"
     ]
    }
   ],
   "source": [
    "if mark_videos_from_old_list:\n",
    "    mark_from_videos()\n",
    "\n",
    "if mark_videos_from_comment_files:\n",
    "    mark_from_comments()\n",
    "    mark_from_Manual_comments()\n",
    "    \n",
    "export(combined_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
