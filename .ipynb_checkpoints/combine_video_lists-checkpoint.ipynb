{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Combine Video Lists generated with the [YouTube Data Tools](https://tools.digitalmethods.net/netvizz/youtube/index.php) \n",
    "## Usage\n",
    "\n",
    "1. go to the Variables Section below and Set/Check the desired Values. make sure the relative Paths are correct.\n",
    "2. Activate / Deactivate the desiredi Features\n",
    "3. Run the script, read output to find issues\n",
    "\n",
    "## Features\n",
    "\n",
    "- Combines Video Lists from  [YouTube Data Tools](https://tools.digitalmethods.net/netvizz/youtube/index.php) into one Master List\n",
    "- Removes Duplicate Video Entrys\n",
    "- Can Mark Downloaded Video Comments based on downloaded comment files (if video Id is included)\n",
    "- Can Mark Downloaded Video Comments based on previously created and marked master Video List\n",
    "- Can Split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set Variables and options\n",
    "\n",
    "### Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Path in case of Error C:\\Users\\moritz\\Downloads\\social analizing\\project\\git\\social_media_youtube_analysis_project\n"
     ]
    }
   ],
   "source": [
    "min_Comments = 3.0\n",
    "\n",
    "split_comment_count = 10000.0\n",
    "\n",
    "path = os.path.abspath(\"../social_media_youtube_analysis_project\")\n",
    "data_raw_path = path + \"/data_raw/videolists\" # raw video lists\n",
    "video_list_save_path = path + \"/summery_vid_lists\"\n",
    "comment_saves_path = path + \"/data_raw/comments\"\n",
    "comment_manual_saves_path = path + \"/data_raw/datatool_manual\"\n",
    "\n",
    "print(\"Check Path in case of Error \" + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_videos_from_old_list = True\n",
    "use_only_newest_video_master_list = False\n",
    "\n",
    "\n",
    "mark_videos_from_comment_files = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle Liste der Videolisten und checken der Pfade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    raise ValueError(\"Error, Check Path in 'path' variable\")\n",
    "if not os.path.exists(data_raw_path):\n",
    "    raise ValueError(\"Error, Check Path in 'data_raw_path' variable\")\n",
    "if not os.path.exists(video_list_save_path):\n",
    "    raise ValueError(\"Error, Check Path in 'video_list_save_path' variable\")\n",
    "if not os.path.exists(video_list_save_path) and mark_videos_from_comment_files:\n",
    "    raise ValueError(\"Error, Check Path in 'video_list_save_path' variable\")\n",
    "\n",
    "files = [f for f in os.listdir(data_raw_path) if os.path.isfile(os.path.join( data_raw_path , f)) and \"videolist\" in f]\n",
    "\n",
    "if not files:\n",
    "    raise ValueError('Error List is empty, no video Lists have been found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine files and insert columns for marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_csv = pd.concat([pd.read_csv(data_raw_path +\"/\" + f, sep='\\t',header=(0)) for f in files ])\n",
    "def searchtermFromFile(filename):\n",
    "    name = filename.split(\"_\")\n",
    "    name = name[7:]\n",
    "    name = \" \".join(name)\n",
    "    name = name[:-4]\n",
    "    return name\n",
    "\n",
    "firstfile = files.pop()\n",
    "combined_csv = pd.read_csv(data_raw_path +\"/\" + firstfile, sep='\\t',header=(0))\n",
    "combined_csv['search_Term'] = searchtermFromFile(firstfile)\n",
    "combined_csv['Comments_Downloaded'] = \"False\"\n",
    "combined_csv['Comments_Downloaded_Stopped_At'] = 0\n",
    "\n",
    "for filename in files:\n",
    "    filepath = data_raw_path +\"/\" + filename\n",
    "    add_csv = pd.read_csv(data_raw_path +\"/\" + filename, sep='\\t',header=(0))\n",
    "    add_csv['search_Term'] = searchtermFromFile(filename)\n",
    "    add_csv['Comments_Downloaded'] = \"False\"\n",
    "    add_csv['Comments_Downloaded_Stopped_At'] = 0\n",
    "    combined_csv = pd.concat([combined_csv, add_csv])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop duplicate videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.drop_duplicates(subset =\"videoId\", \n",
    "                     keep = False, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop videos below comment minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.drop(combined_csv[combined_csv.commentCount < min_Comments].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funktion to Export as CSV with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(export_csf):\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    " \n",
    "    # time Format\n",
    "    # YY-mm-dd-H-M-S\n",
    "    dt_string = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "    # in case path does not exist\n",
    "    if not os.path.exists(path + \"/summery_vid_lists/\"):\n",
    "        os.makedirs(path + \"/summery_vid_lists/\")\n",
    "\n",
    "    # export complete list\n",
    "    export_csf.to_csv( video_list_save_path + \"/\" + dt_string + \"_master_video_list_all.csv\", index=False, encoding='utf-8-sig', sep='\\t')\n",
    "    print(\"Complete List Exported to \" + video_list_save_path + \"/\" + dt_string + \"_master_video_list_all.csv\")\n",
    "    \n",
    "    # split by comment value\n",
    "    export_csf.sort_values(by=['commentCount'],inplace=True, axis=0,ignore_index = True,  na_position = 'first')\n",
    "    csv = export_csf\n",
    "\n",
    "    index = csv[csv.commentCount >=split_comment_count].first_valid_index()\n",
    "  \n",
    "    df1 = csv[:index]\n",
    "    df2 = csv[index:]\n",
    "    \n",
    "    \n",
    "    df1.to_csv( video_list_save_path + \"/\" + dt_string + \"_master_video_list_below_\" + str(int(split_comment_count)) + \".csv\", index=False, encoding='utf-8-sig', sep='\\t')\n",
    "    print(\"Complete List Exported to \" + video_list_save_path + \"/\" + dt_string + \"_master_video_list_below_\" + str(int(split_comment_count)) + \".csv\")\n",
    "    \n",
    "    df2.to_csv( video_list_save_path + \"/\" + dt_string + \"_master_video_list_above_\" + str(int(split_comment_count)) + \".csv\", index=False, encoding='utf-8-sig', sep='\\t')\n",
    "    print(\"Complete List Exported to \" + video_list_save_path + \"/\" + dt_string + \"_master_video_list_above_\" + str(int(split_comment_count)) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion to mark videos from old list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_from_videos():\n",
    "    # function requires filles combined_csv variable\n",
    "    files = [f for f in os.listdir(video_list_save_path) if os.path.isfile(os.path.join( video_list_save_path , f)) and \"master_video_list_all\" in f]\n",
    "    files = sorted(files)\n",
    "    print(files)\n",
    "    if use_only_newest_video_master_list:\n",
    "        files = [files[-1]]\n",
    "    for filename in files:\n",
    "        filepath =  video_list_save_path +\"/\" + filename\n",
    "        csv = pd.read_csv(filepath,header=(0))\n",
    "\n",
    "        if 'Comments_Downloaded' in csv.columns:\n",
    "            csv = csv[csv.Comments_Downloaded == True]\n",
    "            for index, row in csv.iterrows():\n",
    "                combined_csv.loc[combined_csv.videoId == row.videoId, 'Comments_Downloaded'] = True\n",
    "    print(\"mark_from_videos finished\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion to mark videos from comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_from_comments():\n",
    "    files = [f for f in os.listdir(comment_saves_path) if os.path.isfile(os.path.join( comment_saves_path , f)) and \"comment\" in f]\n",
    "    for filename in files:\n",
    "        filepath =  comment_saves_path +\"/\" + filename\n",
    "        try:\n",
    "            csv = pd.read_csv(filepath,header=(0))\n",
    "            if 'video_id' in csv.columns:\n",
    "                csv = csv.drop_duplicates('video_id', keep='last')\n",
    "                for index, row in csv.iterrows():\n",
    "                    combined_csv.loc[combined_csv.videoId == row.video_id, 'Comments_Downloaded'] = True\n",
    "            else:\n",
    "                print(\"File \" + filename + \" has no column video_id, videos not marked in list, column names are:\")\n",
    "                print(\" \")\n",
    "                print(list(csv.columns) )\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(\"Unicode Error in file \" + filename + \" Re-Save in UTF 8, could be an unprocessed manual download\") \n",
    "    print(\"mark_from_comments finished\")\n",
    "    print(\" \")\n",
    "    \n",
    "def mark_from_Manual_comments():\n",
    "    # manuel video list from comments folder\n",
    "    files = [f for f in os.listdir(comment_saves_path) if os.path.isfile(os.path.join( comment_saves_path , f)) and \"comment\" in f and \"videoinfo\" in f]\n",
    "    \n",
    "    # manuel video list from data tools folder\n",
    "    files = files + [f for f in os.listdir(comment_manual_saves_path) if os.path.isfile(os.path.join( comment_manual_saves_path , f)) and \"comment\" in f and \"videoinfo\" in f]\n",
    "    \n",
    "    # remove double entrys\n",
    "    files = list(dict.fromkeys(files))\n",
    "       \n",
    "    for filename in files:\n",
    "        # extract video id\n",
    "        file =  filename[10:]\n",
    "        videoId = file[:file.find(\"_202\")]\n",
    "        \n",
    "        # mark video\n",
    "        combined_csv.loc[combined_csv.videoId == videoId, 'Comments_Downloaded'] = True\n",
    "     \n",
    "    print(\"mark_from_comments_manual finished\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply features and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 16 fields in line 3, saw 83\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f0b183cc8b13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmark_videos_from_old_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmark_from_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmark_videos_from_comment_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmark_from_comments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-8fb5b9909dc8>\u001b[0m in \u001b[0;36mmark_from_videos\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mvideo_list_save_path\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mcsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'Comments_Downloaded'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\moritz\\anaconda3\\envs\\social-2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\moritz\\anaconda3\\envs\\social-2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\moritz\\anaconda3\\envs\\social-2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\moritz\\anaconda3\\envs\\social-2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 16 fields in line 3, saw 83\n"
     ]
    }
   ],
   "source": [
    "if mark_videos_from_old_list:\n",
    "    mark_from_videos()\n",
    "\n",
    "if mark_videos_from_comment_files:\n",
    "    mark_from_comments()\n",
    "    mark_from_Manual_comments()\n",
    "    \n",
    "export(combined_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
